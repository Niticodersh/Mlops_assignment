{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# B21AI056 MLOps Quantization ML Assignment\n",
        "MLFlow Report Available at https://dagshub.com/Niticodersh/Mlops_assignment.mlflow/#/experiments/2/runs/436d626a18a1453589f781f1b30fbc77"
      ],
      "metadata": {
        "id": "511uFGqdOWMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "fuQbVflfMQTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install mlflow\n",
        "!pip install dagshub"
      ],
      "metadata": {
        "id": "oJPEdDj1IJN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28FksNYlMOm_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import dagshub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dagshub.init(repo_owner='Niticodersh', repo_name='Mlops_assignment', mlflow=True)\n",
        "mlflow.set_experiment(\"Quantized Machine Learning\")\n",
        "\n",
        "remote_server_uri = 'https://dagshub.com/Niticodersh/Mlops_assignment.mlflow'\n",
        "mlflow.set_registry_uri(remote_server_uri)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "jRU-MjY5Ipoh",
        "outputId": "0d47d6a8-88cf-446b-b20a-a408fdaa8e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"Niticodersh/Mlops_assignment\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Niticodersh/Mlops_assignment\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository Niticodersh/Mlops_assignment initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Niticodersh/Mlops_assignment initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.start_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3DPeFt4JDrB",
        "outputId": "a067e3a7-cf16-4bbe-f16d-7bc0e92fb164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ActiveRun: >"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "KN-WMlDKM-a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "clW4GL47PAed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "oMeoR8xWNOCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionModel(nn.Module):\n",
        "  def __init__(self, input_dim, num_classes):\n",
        "    super(LogisticRegressionModel, self).__init__()\n",
        "    self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # return torch.softmax(self.linear(x), dim=1)\n",
        "    return self.linear(x)\n",
        "\n",
        "#Model Initialization\n",
        "input_size = X.shape[1]\n",
        "print(f'Input size = {input_size}')\n",
        "num_classes = len(np.unique(y_train))\n",
        "print(f'Number of classes = {num_classes}')\n",
        "model = LogisticRegressionModel(input_size, num_classes)\n",
        "print(f'Model Architecture : \\n {model}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWDIPWavNNxm",
        "outputId": "6b892fec-4444-4f79-ddfc-427bea6041fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size = 64\n",
            "Number of classes = 10\n",
            "Model Architecture : \n",
            " LogisticRegressionModel(\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transformation"
      ],
      "metadata": {
        "id": "dQ9a19RIPMp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "print(len(X_train_tensor))\n",
        "print(len(X_test_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trl3vluxPiPt",
        "outputId": "acc08e1a-137c-4c85-d7f3-9f9064946aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1437\n",
            "360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "13w7WJOQRBy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Logistic Regression Model"
      ],
      "metadata": {
        "id": "oa-1yhbxOyhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "plot_train_losses = []\n",
        "plot_test_losses = []\n",
        "best_test_loss = float('inf')\n",
        "epochs = 100\n",
        "\n",
        "# Log hyperparameters\n",
        "mlflow.log_param(\"batch_size\", batch_size)\n",
        "mlflow.log_param(\"epochs\", epochs)\n",
        "mlflow.log_param(\"learning_rate\", 0.01)\n",
        "mlflow.log_param(\"optimizer\", \"SGD\")\n",
        "mlflow.log_param(\"loss_function\", \"CrossEntropyLoss\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL6cJ3RYJbUx",
        "outputId": "6f11b0ea-8a3b-49fe-e66c-ec5eb1dbdbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_train_loss = 0.0\n",
        "  for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "  train_loss = running_train_loss/len(train_loader)\n",
        "  plot_train_losses.append(train_loss)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    running_test_loss = 0.0\n",
        "    for batch_idx, (inputs, labels) in enumerate(test_loader):\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      running_test_loss += loss.item()\n",
        "\n",
        "  test_loss = running_test_loss/len(test_loader)\n",
        "  plot_test_losses.append(test_loss)\n",
        "\n",
        "  # Log losses for each epoch\n",
        "  mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "  mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
        "\n",
        "  if test_loss < best_test_loss:\n",
        "    best_test_loss = test_loss\n",
        "    torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    print(f'Epoch [{epoch}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rElX6hI6Os5w",
        "outputId": "ddd7583c-519f-4522-98e8-0e0465ad4da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], Train Loss: 2.2017, Test Loss: 1.9907\n",
            "Epoch [10/100], Train Loss: 0.6952, Test Loss: 0.6927\n",
            "Epoch [20/100], Train Loss: 0.4590, Test Loss: 0.4644\n",
            "Epoch [30/100], Train Loss: 0.3592, Test Loss: 0.3683\n",
            "Epoch [40/100], Train Loss: 0.3030, Test Loss: 0.3147\n",
            "Epoch [50/100], Train Loss: 0.2700, Test Loss: 0.2802\n",
            "Epoch [60/100], Train Loss: 0.2421, Test Loss: 0.2558\n",
            "Epoch [70/100], Train Loss: 0.2259, Test Loss: 0.2376\n",
            "Epoch [80/100], Train Loss: 0.2070, Test Loss: 0.2232\n",
            "Epoch [90/100], Train Loss: 0.1935, Test Loss: 0.2117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(plot_train_losses, label='Train Loss')\n",
        "plt.plot(plot_test_losses, label='Test Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss_plot.png')\n",
        "mlflow.log_artifact('loss_plot.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "d3-XOevgT8cA",
        "outputId": "0de63b14-ed74-4b9e-81ac-d1ae64db9d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the best model"
      ],
      "metadata": {
        "id": "Ehm70txXXbdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegressionModel(input_size, num_classes)\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "mlflow.pytorch.log_model(model, \"best_model\")\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0aIVtd8XI_4",
        "outputId": "d807a368-a676-4805-d14a-65443856d83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-5125bb40a550>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n",
            "2024/10/15 18:21:47 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:21:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:21:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionModel(\n",
              "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Inferencing"
      ],
      "metadata": {
        "id": "furBHy07btW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader):\n",
        "  start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "    test_outputs = torch.softmax(model(X_test_tensor), dim=1)\n",
        "    _, predicted = torch.max(test_outputs, dim=1)\n",
        "    accuracy = (predicted == y_test_tensor).sum().item()/len(y_test_tensor) * 100\n",
        "  end_time = time.time()\n",
        "  inference_time = end_time - start_time\n",
        "  print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
        "  print(f\"Accuracy: {accuracy:.4f}%\")\n",
        "\n",
        "  return inference_time, accuracy"
      ],
      "metadata": {
        "id": "YP4tsaUIfUZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_size(model, quantized=False):\n",
        "  total_size = 0\n",
        "  total_params = 0\n",
        "  if quantized==False:\n",
        "     for layer in model.children():\n",
        "        if hasattr(layer, 'weight') and layer.weight is not None:\n",
        "          weight_tensor = layer.weight.data\n",
        "          weight_size = len(weight_tensor.flatten())\n",
        "          total_params+= weight_size\n",
        "          if weight_tensor.dtype == torch.float32:\n",
        "            total_size+= weight_size * 4\n",
        "          elif weight_tensor.dtype == torch.int8:\n",
        "            total_size+= weight_size * 1\n",
        "          elif weight_tensor.dtype == torch.int32:\n",
        "            total_size+= weight_size * 4\n",
        "          elif weight_tensor.dtype == torch.int64:\n",
        "            total_size+= weight_size * 8\n",
        "          elif weight_tensor.dtype == torch.float64:\n",
        "            total_size+= weight_size * 8\n",
        "\n",
        "\n",
        "        if hasattr(layer, 'bias') and layer.bias is not None:\n",
        "          bias_tensor = layer.bias.data\n",
        "          bias_size = len(bias_tensor.flatten())\n",
        "          total_params+= bias_size\n",
        "          if bias_tensor.dtype == torch.float32:\n",
        "            total_size+= bias_size * 4\n",
        "          elif bias_tensor.dtype == torch.int8:\n",
        "            total_size+= bias_size * 1\n",
        "          elif bias_tensor.dtype == torch.int32:\n",
        "            total_size+= bias_size * 4\n",
        "          elif bias_tensor.dtype == torch.int64:\n",
        "            total_size+= bias_size * 8\n",
        "          elif bias_tensor.dtype == torch.float64:\n",
        "            total_size+= bias_size * 8\n",
        "\n",
        "  else:\n",
        "    for layer in model.children():\n",
        "      if hasattr(layer, 'weight') and layer.weight is not None:\n",
        "        weight_tensor = layer.weight()\n",
        "        weight_size = len(weight_tensor.flatten())\n",
        "        total_params+= weight_size\n",
        "\n",
        "        if weight_tensor.dtype == torch.qint8:\n",
        "          total_size+= weight_size * 1\n",
        "        elif weight_tensor.dtype == torch.qint32:\n",
        "          total_size+= weight_size * 4\n",
        "\n",
        "\n",
        "      if hasattr(layer, 'bias') and layer.bias is not None:\n",
        "        bias_tensor = layer.bias()\n",
        "        bias_size = len(bias_tensor.flatten())\n",
        "        total_params+= bias_size\n",
        "        if bias_tensor.dtype == torch.qint8:\n",
        "          total_size+= bias_size * 1\n",
        "        elif bias_tensor.dtype == torch.qint32:\n",
        "          total_size+= bias_size * 4\n",
        "        elif bias_tensor.dtype == torch.float32:\n",
        "          total_size+= bias_size * 4\n",
        "        elif bias_tensor.dtype == torch.int8:\n",
        "          total_size+= bias_size * 1\n",
        "        elif bias_tensor.dtype == torch.int32:\n",
        "          total_size+= bias_size * 4\n",
        "        elif bias_tensor.dtype == torch.int64:\n",
        "          total_size+= bias_size * 8\n",
        "        elif bias_tensor.dtype == torch.float64:\n",
        "          total_size+= bias_size * 8\n",
        "\n",
        "  print(f\"Number of model parameters: {total_params}\")\n",
        "\n",
        "  print(f\"Model size: {total_size} Bytes\")\n",
        "\n",
        "  return total_params, total_size"
      ],
      "metadata": {
        "id": "UbvgXBLofbgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inf_time1, acc1 = test_model(model, test_loader)\n",
        "mlflow.log_metric(\"inference_time_original\", inf_time1)\n",
        "mlflow.log_metric(\"accuracy_original\", acc1)\n",
        "params1, size1 = model_size(model)\n",
        "mlflow.log_metric(\"original_model_params\", params1)\n",
        "mlflow.log_metric(\"original_model_size_bytes\", size1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JYa0jL-n8DN",
        "outputId": "633ebf5a-9c6e-44fb-adef-5a0c2e9c52d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 0.0019 seconds\n",
            "Accuracy: 95.8333%\n",
            "Number of model parameters: 650\n",
            "Model size: 2600 Bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantize Model"
      ],
      "metadata": {
        "id": "XCni-NaUfobJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_quantize_model(model):\n",
        "    quantized_model = torch.quantization.quantize_dynamic(\n",
        "        model, {nn.Linear}, dtype=torch.qint8\n",
        "    )\n",
        "    return quantized_model\n",
        "\n",
        "# Apply dynamic quantization\n",
        "quantized_model1 = dynamic_quantize_model(model)\n",
        "\n",
        "# Save and log the quantized model\n",
        "torch.save(quantized_model1.state_dict(), 'dynamic_quantized_model.pth')\n",
        "mlflow.pytorch.log_model(quantized_model1, \"dynamic_quantized_model\")\n"
      ],
      "metadata": {
        "id": "MFHL1ceB3Sme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe76e94-d5d3-49c8-e5a3-4e9ed695ca92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/15 18:21:59 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:22:04 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:22:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x78caec4def50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def static_quantize_model(model, calibration_data):\n",
        "    # Prepare the model for static quantization\n",
        "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "    torch.quantization.prepare(model, inplace=True)\n",
        "\n",
        "    # Calibrate the model with sample input data\n",
        "    model(calibration_data)\n",
        "\n",
        "    # Convert the model to quantized form\n",
        "    quantized_model = torch.quantization.convert(model, inplace=False)\n",
        "    return quantized_model\n",
        "\n",
        "# Assuming you have calibration_data\n",
        "quantized_model2 = static_quantize_model(model, calibration_data = X_train_tensor[:100])\n",
        "\n",
        "# Save and log the quantized model\n",
        "torch.save(quantized_model2.state_dict(), 'static_quantized_model.pth')\n",
        "mlflow.pytorch.log_model(quantized_model2, \"static_quantized_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ8kIpnRXbgU",
        "outputId": "924b4f40-53e2-43cd-c4d2-50d21db485bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "2024/10/15 18:22:07 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:22:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:22:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x78caec59ffa0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def qat_quantize_model(model, num_epochs, data_loader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    # Prepare the model for quantization-aware training\n",
        "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "    torch.quantization.prepare_qat(model, inplace=True)\n",
        "\n",
        "    # Train the model with QAT (example training loop)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Convert to quantized model after QAT\n",
        "    quantized_model = torch.quantization.convert(model.eval(), inplace=False)\n",
        "    return quantized_model\n",
        "\n",
        "# Assuming you have num_epochs, data_loader, optimizer, and loss_fn defined\n",
        "quantized_model3 = qat_quantize_model(model, epochs, train_loader, optimizer, criterion)\n",
        "\n",
        "# Save and log the quantized model\n",
        "torch.save(quantized_model3.state_dict(), 'qat_quantized_model.pth')\n",
        "mlflow.pytorch.log_model(quantized_model3, \"qat_quantized_model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh3EbYyPXi4d",
        "outputId": "de83ff67-7128-4893-9df0-1fc7a6380054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/15 18:22:19 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:22:23 WARNING mlflow.utils.requirements_utils: Found torch version (2.4.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.4.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
            "2024/10/15 18:22:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlflow.models.model.ModelInfo at 0x78caec349060>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layers Type Checking and Validating Quantization Process"
      ],
      "metadata": {
        "id": "47sjtE991rQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qunatized_value = quantized_model1.linear.weight().int_repr().flatten()[0].item()\n",
        "scale_factor = quantized_model1.linear.weight().q_scale()\n",
        "zero_point = quantized_model1.linear.weight().q_zero_point()\n",
        "original_value = quantized_model1.linear.weight().flatten()[0].item()\n",
        "print(\"Quantized value type:\", quantized_model1.linear.weight().dtype)\n",
        "print(f'Quantized Value : {qunatized_value}')\n",
        "print(f'Scale Factor : {scale_factor}')\n",
        "print(f'Zero Point : {zero_point}')\n",
        "print(f'Original Value : {original_value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9nHxKDP1pmr",
        "outputId": "7632c7c4-8472-4742-b7c7-0af10577ecdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized value type: torch.qint8\n",
            "Quantized Value : 26\n",
            "Scale Factor : 0.004505508113652468\n",
            "Zero Point : 0\n",
            "Original Value : 0.11714321374893188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual Checking\n",
        "(original_value - zero_point)/scale_factor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiZgQlPF5rA0",
        "outputId": "de668179-8141-4f93-8f5d-94de55948892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.00000062012267"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantized Model Inferencing"
      ],
      "metadata": {
        "id": "4fwbBDiQo-vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For quantized_model2\n",
        "inf_time2, acc2 = test_model(quantized_model1, test_loader)\n",
        "mlflow.log_metric(\"inference_time_quantized_model2\", inf_time2)\n",
        "mlflow.log_metric(\"accuracy_quantized_model2\", acc2)\n",
        "params2, size2 = model_size(quantized_model1, quantized=True)\n",
        "mlflow.log_metric(\"quantized_model2_params\", params2)\n",
        "mlflow.log_metric(\"quantized_model2_size_bytes\", size2)\n",
        "\n",
        "# # For quantized_model3\n",
        "# inf_time3, acc3 = test_model(quantized_model2, test_loader)\n",
        "# mlflow.log_metric(\"inference_time_quantized_model3\", inf_time3)\n",
        "# mlflow.log_metric(\"accuracy_quantized_model3\", acc3)\n",
        "# params3, size3 = model_size(quantized_model2, quantized=True)\n",
        "# mlflow.log_metric(\"quantized_model3_params\", params3)\n",
        "# mlflow.log_metric(\"quantized_model3_size_bytes\", size3)\n",
        "\n",
        "# For quantized_model4\n",
        "inf_time4, acc4 = test_model(quantized_model3, test_loader)\n",
        "mlflow.log_metric(\"inference_time_quantized_model4\", inf_time4)\n",
        "mlflow.log_metric(\"accuracy_quantized_model4\", acc4)\n",
        "params4, size4 = model_size(quantized_model3, quantized=True)\n",
        "mlflow.log_metric(\"quantized_model4_params\", params4)\n",
        "mlflow.log_metric(\"quantized_model4_size_bytes\", size4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_zyQNCtioULt",
        "outputId": "5128ea58-c24b-4f0e-bb88-e1a5dfa1ddb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Time: 0.0060 seconds\n",
            "Accuracy: 95.8333%\n",
            "Number of model parameters: 650\n",
            "Model size: 680 Bytes\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Could not run 'quantized::linear' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qlinear.cpp:1317 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Linear.cpp:359 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-461079bed2d9>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# For quantized_model4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0minf_time4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantized_model3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inference_time_quantized_model4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_time4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy_quantized_model4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-6de865917573>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-aa09d197f68f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# return torch.softmax(self.linear(x), dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Model Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/ao/nn/quantized/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         return torch.ops.quantized.linear(\n\u001b[0m\u001b[1;32m    169\u001b[0m             x, self._packed_params._packed_params, self.scale, self.zero_point)\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::linear' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qlinear.cpp:1317 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Linear.cpp:359 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Comparison"
      ],
      "metadata": {
        "id": "ds-oUOl8AZbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Data for the original and quantized models\n",
        "model_names = ['Original Model', 'Quantized Model 2', 'Quantized Model 3', 'Quantized Model 4']\n",
        "inf_times = [inf_time1, inf_time2, inf_time3, inf_time4]\n",
        "accuracies = [acc1, acc2, acc3, acc4]\n",
        "params = [params1, params2, params3, params4]\n",
        "sizes = [size1, size2, size3, size4]\n",
        "\n",
        "# Create a figure with 4 subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Subplot for Inference Time\n",
        "sns.barplot(x=model_names, y=inf_times, ax=axs[0, 0], palette=\"Blues_d\")\n",
        "axs[0, 0].set_title('Inference Time')\n",
        "axs[0, 0].set_ylabel('Time (s)')\n",
        "axs[0, 0].set_xticklabels(model_names, rotation=30)\n",
        "\n",
        "# Subplot for Accuracy\n",
        "sns.barplot(x=model_names, y=accuracies, ax=axs[0, 1], palette=\"Greens_d\")\n",
        "axs[0, 1].set_title('Accuracy')\n",
        "axs[0, 1].set_ylabel('Accuracy (%)')\n",
        "axs[0, 1].set_xticklabels(model_names, rotation=30)\n",
        "\n",
        "# Subplot for Number of Parameters\n",
        "sns.barplot(x=model_names, y=params, ax=axs[1, 0], palette=\"Reds_d\")\n",
        "axs[1, 0].set_title('Number of Parameters')\n",
        "axs[1, 0].set_ylabel('Parameters (count)')\n",
        "axs[1, 0].set_xticklabels(model_names, rotation=30)\n",
        "\n",
        "# Subplot for Model Size\n",
        "sns.barplot(x=model_names, y=sizes, ax=axs[1, 1], palette=\"Purples_d\")\n",
        "axs[1, 1].set_title('Model Size (bytes)')\n",
        "axs[1, 1].set_ylabel('Size (bytes)')\n",
        "axs[1, 1].set_xticklabels(model_names, rotation=30)\n",
        "\n",
        "# Adjust layout for better spacing\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tVxRyrPorVPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "Gu2pXjuKaHQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}